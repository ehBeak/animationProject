{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYcjWx/oCE2Xsy6VK2IDnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehBeak/animationProject/blob/main/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CntlwzErodsV"
      },
      "source": [
        "import cv2 as cv\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc4tmBB6pDKn"
      },
      "source": [
        "모델 다운"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T4elcXSjc91"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1ErIAsB_miVhYL9GDlYUmfbqlV293mSYf -O model.pth -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBb9jdwTqxvI"
      },
      "source": [
        "모델 실행 코드 클론"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS62YrLakkHS"
      },
      "source": [
        "!git clone -q https://github.com/PeterL1n/BackgroundMattingV2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_FE0BO7TCg7",
        "outputId": "69f62e17-0ff9-411d-e738-7c209c688d73"
      },
      "source": [
        "#mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9jMwQWUpLMe"
      },
      "source": [
        "content 이동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "QtoKTUsLq1aV",
        "outputId": "d8eff72f-5405-40a7-bed7-d4e7b5966bf0"
      },
      "source": [
        "%cd /content\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyNekSG6pQKA"
      },
      "source": [
        "input 비디오의 첫 프레임 잘라서 content에 test.png로 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLfr-HuenHJ3"
      },
      "source": [
        "vidcap = cv.VideoCapture('src.mp4')\n",
        "\n",
        "if(vidcap.isOpened()): \n",
        "  ret, image = vidcap.read()\n",
        "  cv.imwrite(\"./test.png\",image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2UrB8e0pY_j"
      },
      "source": [
        "BackgroundMattingV2 파일로 이동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DmWNMkbrazx",
        "outputId": "6dfe4f84-a4f1-4f7a-ed25-85c3c7b02740"
      },
      "source": [
        "os.getcwd()\n",
        "%cd BackgroundMattingV2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BackgroundMattingV2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnmA85UarGx5"
      },
      "source": [
        "학습된 모델 실행, 결과값은 ouput에"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1adsCQqtkpE7",
        "outputId": "40c3559c-dd52-4b58-8f55-43a59d12fbe1"
      },
      "source": [
        "!python inference_video.py \\\n",
        "        --model-type mattingrefine \\\n",
        "        --model-backbone resnet50 \\\n",
        "        --model-backbone-scale 0.25 \\\n",
        "        --model-refine-mode sampling \\\n",
        "        --model-refine-sample-pixels 80000 \\\n",
        "        --model-checkpoint \"/content/model.pth\" \\\n",
        "        --video-src \"/content/src.mp4\" \\\n",
        "        --video-bgr \"/content/test.png\" \\\n",
        "        --output-dir \"/content/test/\" \\\n",
        "        --output-type com fgr pha err ref"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/341 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "100% 341/341 [00:22<00:00, 15.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9wdYOYRpjsv"
      },
      "source": [
        "ouput으로 이동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj2V7Lg4uHK3",
        "outputId": "929e7965-b01b-483f-d52b-0a297f5e45c2"
      },
      "source": [
        "os.getcwd()\n",
        "%cd /content/test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSyYCplKqJCq"
      },
      "source": [
        "초록 부분 배경 제거\n",
        "\n",
        "\n",
        "1.   com을 각각 frame 단위로 자르기\n",
        "2.   pha을 각각 frame 단위로 자르기\n",
        "3.   자른 pha를 가지고 mask 만들기\n",
        "4.   com에 mask 씌우기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIIqLMIEIGmd"
      },
      "source": [
        "# 1 com을 각각 frame 단위로 자르기(com)\n",
        "os.getcwd()\n",
        "%cd /content/test\n",
        "\n",
        "vidcap = cv.VideoCapture('com.mp4')\n",
        "sucess, image = vidcap.read()\n",
        "\n",
        "count = 1\n",
        "sucess = True\n",
        "\n",
        "while sucess:\n",
        "  sucess, image = vidcap.read()\n",
        "  cv.imwrite('/content/com/%d.png' % count, image)\n",
        "  print(\"saved image %d.png\" % count)\n",
        "\n",
        "  if cv.waitKey(0) == 27:\n",
        "    break\n",
        "  count += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "39640kpjEQd9",
        "outputId": "b93b0afc-48ae-4ba6-db66-3e5aebad3815"
      },
      "source": [
        "# pha를 각각 프레임 단위로 자르기\n",
        "# mask만들고 hsv로 출력\n",
        "import numpy as np\n",
        "\n",
        "os.getcwd()\n",
        "%cd /content/test\n",
        "\n",
        "vidcap = cv.VideoCapture('pha.mp4')\n",
        "sucess, image = vidcap.read()\n",
        "\n",
        "count = 1\n",
        "sucess = True\n",
        "\n",
        "while sucess:\n",
        "  sucess, image = vidcap.read()\n",
        "  cv.imwrite('/content/pha/%d.png' % count, image)\n",
        " # print(\"saved image %d.png\" % count)\n",
        "\n",
        "  phaimg = cv.imread('/content/pha/%d.png' % count, cv.IMREAD_UNCHANGED)\n",
        "  mask = np.zeros_like(phaimg)\n",
        "  masked = cv.bitwise_or(phaimg, mask)\n",
        "  masked = cv.cvtColor(phaimg, cv.COLOR_BGR2HSV)\n",
        "  masked = cv.cvtColor(phaimg, cv.COLOR_HSV2BGR)\n",
        "  cv.imwrite('/content/mask/%d.png' % count, masked)\n",
        "\n",
        "  h, s, v = cv.split(masked)\n",
        "\n",
        "  lower_red = cv.inRange(masked, (0,128,0),(100,255,100))\n",
        "  upper_red = cv.inRange(masked,(50,150,0), (80,255,255))\n",
        "  added_red = cv.addWeighted(lower_red, 1.0, upper_red, 1.0, 0.0)\n",
        "\n",
        "  red = cv.bitwise_and(masked, masked, mask=added_red)\n",
        "  #red = cv.cvtColor(red, cv.COLOR_HSV2BGR)\n",
        "  cv.imwrite('/content/masked/%d.png' % count, red)\n",
        "\n",
        "  if cv.waitKey(0) == 27:\n",
        "    break\n",
        "  count += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/test\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-269e2633aeed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0msucess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0msucess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/pha/%d.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m  \u001b[0;31m# print(\"saved image %d.png\" % count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgcodecs/src/loadsave.cpp:715: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzluJA5tI_K1"
      },
      "source": [
        "# 3.pha로 마스크 만들기(hvs 설정 잘하기)\n",
        "\n",
        "phaimg = cv.imread('.png', cv.IMREAD_UNCHANGED)\n",
        "\n",
        "mask = np.zeros_like(test)\n",
        "\n",
        "masked = cv.bitwise_or(phaimg, mask)\n",
        "\n",
        "cv.imwrite('.png', masked)\n",
        "\n",
        "# BGR -> HSV -> \n",
        "masked = cv.cvtColor(masked, cv.COLOR_BGR2HSV)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ploSgqpuEQFm"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "vidcap = cv.VideoCapture('pha.mp4')\n",
        "sucess, image = vidcap.read()\n",
        "\n",
        "count = 1\n",
        "sucess = True\n",
        "\n",
        "while sucess:\n",
        "  sucess, image = vidcap.read()\n",
        "  cv.imwrite('/content/pha/%d.png' % count, image)\n",
        "  print(\"saved image %d.png\" % count)\n",
        "  image_bgr = cv.imread('/content/pha/%d.png'% count) \n",
        "  h, w, c = image_bgr.shape\n",
        "  image_bgra = np.concatenate([image_bgr, np.full((h, w, 1), 255, dtype=np.uint8)], axis=-1)\n",
        "  white = np.all(image_bgr == [153, 254, 117], axis=-1)\n",
        "  image_bgra[white, -1] = 0\n",
        "  cv.imwrite('/content/pha/%d.png'% count, image_bgra)\n",
        "\n",
        "  if cv.waitKey(0) == 27:\n",
        "    break\n",
        "  count += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "ZDlUmWHLqMcs",
        "outputId": "41aa382e-6906-4f12-b90d-6d7c928d8eed"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# # read the image\n",
        "# image_bgr = cv.imread('./comtest.png')\n",
        "# print(image_bgr)\n",
        "# # get the image dimensions (height, width and channels)\n",
        "# h, w, c = image_bgr.shape\n",
        "# # append Alpha channel -- required for BGRA (Blue, Green, Red, Alpha)\n",
        "# image_bgra = np.concatenate([image_bgr, np.full((h, w, 1), 255, dtype=np.uint8)], axis=-1)\n",
        "# # create a mask where white pixels ([255, 255, 255]) are True\n",
        "# white = np.all(image_bgr == [153, 254, 117], axis=-1)\n",
        "# # change the values of Alpha to 0 for all the white pixels\n",
        "# image_bgra[white, -1] = 0\n",
        "# # save the image\n",
        "# cv.imwrite('image_bgra2.png', image_bgra)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved image 1.png\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6ace5c1bf30d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved image %d.png\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mimage_bgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/image/%d.png'\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_bgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mimage_bgra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_bgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mwhite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_bgr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m217\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m236\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}