{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RVM.ipynb의 사본",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehBeak/animationProject/blob/main/RVM_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJnxd6hdDymV"
      },
      "source": [
        "# Robust High-Resolution Video Matting with Temporal Guidance.\n",
        "\n",
        "![Teaser](https://raw.githubusercontent.com/PeterL1n/RobustVideoMatting/master/documentation/image/teaser.gif)\n",
        "\n",
        "[Project Site](https://peterl1n.github.io/RobustVideoMatting) | [GitHub](https://github.com/PeterL1n/RobustVideoMatting) | [Paper](https://arxiv.org/abs/2108.11515)\n",
        "\n",
        "\n",
        "## Colab Demo\n",
        "This colab notebook is set up to let you quickly test our model on your video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qD01TEQEg1p"
      },
      "source": [
        "### Option 1: Upload your video\n",
        "\n",
        "Run the cell below and upload your own video. (Only tested on .mp4 files)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cGycwzuEgF_"
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()           # Use colab upload dialog.\n",
        "uploaded = list(uploaded.keys())    # Get uploaded filenames.\n",
        "assert len(uploaded) == 1           # Make sure only uploaded one file.\n",
        "os.rename(uploaded[0], 'input.mp4') # Rename file to \"input.mp4\"."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VWKlE6pGa9A"
      },
      "source": [
        "### Option 2: Try our demo video\n",
        "\n",
        "Run the cell below to download our demo video. Skip it if you have uploaded your own video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLonjeynFONz"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1I0v72-hNlK1hm9q1OwyaATUYApXpotS6 -O input.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy5AetvnHYyO"
      },
      "source": [
        "### Start Inference\n",
        "\n",
        "Run the cells below to process your video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FENlcP_UGnBC"
      },
      "source": [
        "!pip install --quiet av pims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhAstublHpze"
      },
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load(\"PeterL1n/RobustVideoMatting\", \"mobilenetv3\").cuda() # or \"resnet50\"\n",
        "convert_video = torch.hub.load(\"PeterL1n/RobustVideoMatting\", \"converter\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQS1RNu3IEl2"
      },
      "source": [
        "convert_video(\n",
        "    model,                           # The loaded model, can be on any device (cpu or cuda).\n",
        "    input_source='input.mp4',        # A video file or an image sequence directory.\n",
        "    downsample_ratio=None,           # [Optional] If None, make downsampled max size be 512px.\n",
        "    output_type='video',             # Choose \"video\" or \"png_sequence\"\n",
        "    output_composition='com.mp4',    # File path if video; directory path if png sequence.\n",
        "    output_alpha=\"pha.mp4\",          # [Optional] Output the raw alpha prediction.\n",
        "    output_foreground=\"fgr.mp4\",     # [Optional] Output the raw foreground prediction.\n",
        "    output_video_mbps=4,             # Output video mbps. Not needed for png sequence.\n",
        "    seq_chunk=12,                    # Process n frames at once for better parallelism.\n",
        "    num_workers=1,                   # Only for image sequence input. Reader threads.\n",
        "    progress=True                    # Print conversion progress.\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iJwFwqUI9Az"
      },
      "source": [
        "### Download results\n",
        "\n",
        "After the processing is done, you can download the results from the files panel on the left.\n",
        "\n",
        "* `com.mp4`: The matting result composited on top of a green screen background.\n",
        "* `pha.mp4`: The raw alpha matte.\n",
        "* `fgr.mp4`: The raw foreground prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePnPhf-x269p"
      },
      "source": [
        "# mask씌우기\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "vidcap = cv.VideoCapture('pha.mp4')\n",
        "sucess, image = vidcap.read()\n",
        "\n",
        "vidcapCom = cv.VideoCapture('com.mp4')\n",
        "sucesscom, imagecom = vidcapCom.read()\n",
        "\n",
        "count = 1\n",
        "sucess = True\n",
        "\n",
        "while sucess:\n",
        "  sucess, image = vidcap.read()\n",
        "  #######\n",
        "  image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
        "  mask = cv.inRange(image,(0,0,210),(359,255,255))\n",
        "  mask = cv.bitwise_not(mask)\n",
        "\n",
        "  #######\n",
        "  sucesscom, imagecom = vidcapCom.read()\n",
        "\n",
        "  #masked = cv.bitwise_and(imagecom, image)\n",
        "  ##\n",
        "  imagecom = cv.cvtColor(imagecom, cv.COLOR_BGR2BGRA)\n",
        "  imagecom[mask>0]=(0,0,0,0)\n",
        "  ##\n",
        "  cv.imwrite('/content/masked/%d.png' % count, imagecom)\n",
        "\n",
        "  \n",
        "\n",
        "  if cv.waitKey(0) == 27:\n",
        "    break\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYHp4bMS5gMD"
      },
      "source": [
        "# 녹색배경 제거\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "vidcapCom = cv.VideoCapture('com.mp4')\n",
        "sucesscom, origin = vidcapCom.read()\n",
        "\n",
        "count = 1\n",
        "sucess = True\n",
        "\n",
        "while sucesscom:\n",
        "  sucesscom, origin = vidcapCom.read()\n",
        "\n",
        "  imagecom = origin\n",
        "\n",
        "  imagecom = cv.cvtColor(imagecom, cv.COLOR_BGR2HSV)\n",
        "  mask = cv.inRange(imagecom,(50,0,0),(80,255,255))\n",
        "  mask = cv.GaussianBlur(mask,(3,3),3,3) \n",
        "  #mask = cv.bitwise_not(mask)\n",
        "  \n",
        "  origin = cv.cvtColor(origin, cv.COLOR_BGR2BGRA)\n",
        "  origin[mask>0]=(0,0,0,0)\n",
        "\n",
        "\n",
        "\n",
        "  cv.imwrite('/content/delete/%d.png' % count, origin)\n",
        "\n",
        "  \n",
        "\n",
        "  if cv.waitKey(0) == 27:\n",
        "    break\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}