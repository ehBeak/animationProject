{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehBeak/animationProject/blob/main/deeplearning1203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yK8uvs4Hu25"
      },
      "source": [
        "# mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezFkpAC04Ljm",
        "outputId": "f0e5de1d-e163-41d9-a1eb-a4c6ab75391c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMzmmw3q4rXn",
        "outputId": "c97112cd-7f3b-4c58-ec47-7557794b6c73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/articulated-animation-main/articulated-animation-main\n"
          ]
        }
      ],
      "source": [
        "# 이동\n",
        "%cd /content/drive/MyDrive/articulated-animation-main/articulated-animation-main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N9f7lDE5dJU"
      },
      "source": [
        "# Dowloading videos and cropping according to precomputed bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQM4b6qYASVK",
        "outputId": "92e436b0-4841-4cf1-aeaf-52a6be8fbcf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'video-preprocessing'...\n",
            "remote: Enumerating objects: 162, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 162 (delta 6), reused 0 (delta 0), pack-reused 150\u001b[K\n",
            "Receiving objects: 100% (162/162), 629.55 KiB | 1.40 MiB/s, done.\n",
            "Resolving deltas: 100% (96/96), done.\n"
          ]
        }
      ],
      "source": [
        "# 클론\n",
        "#!git clone https://github.com/AliaksandrSiarohin/video-preprocessing.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPV_QYdHHU4l",
        "outputId": "6df4da17-1782-4661-f259-d53845f64778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/video-preprocessing\n"
          ]
        }
      ],
      "source": [
        "# 이동\n",
        "#%cd /content/video-preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I8_vleZv5czN",
        "outputId": "72f69a62-3495-45fc-d855-2c5eb38ee4ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting imageio==2.3.0\n",
            "  Downloading imageio-2.3.0-py2.py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting matplotlib==2.2.2\n",
            "  Downloading matplotlib-2.2.2-cp37-cp37m-manylinux1_x86_64.whl (12.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.6 MB 13.2 MB/s \n",
            "\u001b[?25hCollecting numpy==1.15.0\n",
            "  Downloading numpy-1.15.0-cp37-cp37m-manylinux1_x86_64.whl (13.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.8 MB 10.8 MB/s \n",
            "\u001b[?25hCollecting pandas==0.23.4\n",
            "  Downloading pandas-0.23.4-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting Pillow==5.2.0\n",
            "  Downloading Pillow-5.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 39.7 MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting scikit-image==0.14.0\n",
            "  Downloading scikit_image-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.19.2\n",
            "  Downloading scikit_learn-0.19.2-cp37-cp37m-manylinux1_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 35.8 MB/s \n",
            "\u001b[?25hCollecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 1.7 MB/s \n",
            "\u001b[?25hCollecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 6.9 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.2.1\n",
            "  Downloading torchvision-0.2.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.24.0\n",
            "  Downloading tqdm-4.24.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements.txt (line 2)) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==2.2.2->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r requirements.txt (line 7)) (2.6.3)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: dask[array]>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r requirements.txt (line 7)) (2.12.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.0->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[array]>=0.9.0->scikit-image==0.14.0->-r requirements.txt (line 7)) (0.11.2)\n",
            "Collecting PyWavelets>=0.4.0\n",
            "  Downloading PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 36.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=ceae225bc9a4365c921f749d6da1b38d7b2da084ac92eea06bbedb3bd46f520a\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built PyYAML\n",
            "Installing collected packages: numpy, torch, scipy, PyWavelets, Pillow, matplotlib, tqdm, torchvision, scikit-learn, scikit-image, PyYAML, pandas, imageio\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: PyWavelets\n",
            "    Found existing installation: PyWavelets 1.2.0\n",
            "    Uninstalling PyWavelets-1.2.0:\n",
            "      Successfully uninstalled PyWavelets-1.2.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.15.0 which is incompatible.\n",
            "yellowbrick 1.3.post1 requires scikit-learn>=0.20, but you have scikit-learn 0.19.2 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.15.0 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.23.4 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "tifffile 2021.11.2 requires numpy>=1.15.1, but you have numpy 1.15.0 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.24.0 which is incompatible.\n",
            "pymc3 3.11.4 requires pandas>=0.24.0, but you have pandas 0.23.4 which is incompatible.\n",
            "pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.15.0 which is incompatible.\n",
            "pyarrow 3.0.0 requires numpy>=1.16.6, but you have numpy 1.15.0 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "plotnine 0.6.0 requires numpy>=1.16.0, but you have numpy 1.15.0 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you have pandas 0.23.4 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.24.0 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you have pandas 0.23.4 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.15.0 which is incompatible.\n",
            "jaxlib 0.1.71+cuda111 requires numpy>=1.18, but you have numpy 1.15.0 which is incompatible.\n",
            "jax 0.2.25 requires numpy>=1.18, but you have numpy 1.15.0 which is incompatible.\n",
            "jax 0.2.25 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.19.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires numpy>=1.15.4, but you have numpy 1.15.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.24.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.15.0 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 5.2.0 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.15.0 which is incompatible.\n",
            "arviz 0.11.4 requires matplotlib>=3.0, but you have matplotlib 2.2.2 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-5.2.0 PyWavelets-1.1.1 PyYAML-5.1 imageio-2.3.0 matplotlib-2.2.2 numpy-1.15.0 pandas-0.23.4 scikit-image-0.14.0 scikit-learn-0.19.2 scipy-1.1.0 torch-1.4.0 torchvision-0.2.1 tqdm-4.24.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# install requirements\n",
        "!pip install -r requirements.txt\n",
        "#무시해도될듯 일단 오류는\n",
        "#############ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.##############"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I2DXebsjsada",
        "outputId": "c98e69ef-c4c1-439c-c860-7c227bae11aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.0\n",
            "  Using cached numpy-1.16.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "Collecting scikit-image==0.14.2\n",
            "  Using cached scikit_image-0.14.2-cp37-cp37m-manylinux1_x86_64.whl (25.3 MB)\n",
            "Collecting pyside2==5.14.0\n",
            "  Downloading PySide2-5.14.0-5.14.0-cp35.cp36.cp37.cp38-abi3-manylinux1_x86_64.whl (165.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 165.4 MB 79 kB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (1.3.0)\n",
            "Requirement already satisfied: dask[array]>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (2.12.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (1.1.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (2.2.2)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (2.6.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2) (5.2.0)\n",
            "Collecting shiboken2==5.14.0\n",
            "  Downloading shiboken2-5.14.0-5.14.0-cp35.cp36.cp37.cp38-abi3-manylinux1_x86_64.whl (848 kB)\n",
            "\u001b[K     |████████████████████████████████| 848 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[array]>=1.0.0->scikit-image==0.14.2) (0.11.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2) (3.0.6)\n",
            "Installing collected packages: numpy, shiboken2, scikit-image, pyside2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.15.0\n",
            "    Uninstalling numpy-1.15.0:\n",
            "      Successfully uninstalled numpy-1.15.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.14.0\n",
            "    Uninstalling scikit-image-0.14.0:\n",
            "      Successfully uninstalled scikit-image-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires scikit-learn>=0.20, but you have scikit-learn 0.19.2 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.23.4 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.24.0 which is incompatible.\n",
            "pymc3 3.11.4 requires pandas>=0.24.0, but you have pandas 0.23.4 which is incompatible.\n",
            "pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "pyarrow 3.0.0 requires numpy>=1.16.6, but you have numpy 1.16.0 which is incompatible.\n",
            "plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you have pandas 0.23.4 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 2.2.2 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you have pandas 0.23.4 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.16.0 which is incompatible.\n",
            "jaxlib 0.1.71+cuda111 requires numpy>=1.18, but you have numpy 1.16.0 which is incompatible.\n",
            "jax 0.2.25 requires numpy>=1.18, but you have numpy 1.16.0 which is incompatible.\n",
            "jax 0.2.25 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.19.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.23.4 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.24.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 5.2.0 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "arviz 0.11.4 requires matplotlib>=3.0, but you have matplotlib 2.2.2 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.16.0 pyside2-5.14.0 scikit-image-0.14.2 shiboken2-5.14.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip3 install numpy==1.16.0 scikit-image==0.14.2 pyside2==5.14.0\n",
        "\n",
        "#ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'. 이거해결법인듯?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbqq-BcWIbgu"
      },
      "source": [
        "video-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl3RFVr41pAw",
        "outputId": "8a35bb75-ad23-421b-d70f-4eb38aa893f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'video-preprocessing'...\n",
            "remote: Enumerating objects: 162, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 162 (delta 6), reused 0 (delta 0), pack-reused 150\u001b[K\n",
            "Receiving objects: 100% (162/162), 629.55 KiB | 3.46 MiB/s, done.\n",
            "Resolving deltas: 100% (96/96), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AliaksandrSiarohin/video-preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc_MBLIE10Zu",
        "outputId": "b887887f-91ee-41c3-a88e-9b4630d47777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/articulated-animation-main/articulated-animation-main/video-preprocessing\n"
          ]
        }
      ],
      "source": [
        "%cd video-preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH2u3R_H4HfJ",
        "outputId": "1777f141-7fe0-4ccc-d4e8-0d7878858b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-12-09 06:14:58--  https://yt-dl.org/downloads/latest/youtube-dl\n",
            "Resolving yt-dl.org (yt-dl.org)... 95.143.172.170, 2001:1a50:11:0:5f:8f:acaa:177\n",
            "Connecting to yt-dl.org (yt-dl.org)|95.143.172.170|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://yt-dl.org/downloads/2021.06.06/youtube-dl [following]\n",
            "--2021-12-09 06:15:00--  https://yt-dl.org/downloads/2021.06.06/youtube-dl\n",
            "Reusing existing connection to yt-dl.org:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/ytdl-org/youtube-dl/releases/download/2021.06.06/youtube-dl [following]\n",
            "--2021-12-09 06:15:00--  https://github.com/ytdl-org/youtube-dl/releases/download/2021.06.06/youtube-dl\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1039520/1ae5cc00-c66b-11eb-8853-1cd0f5317557?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211209T061500Z&X-Amz-Expires=300&X-Amz-Signature=d5c0630e4ceb1a111516ecc5e5778bbfec11cb40a4e51df33cdfe26736b29e9e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1039520&response-content-disposition=attachment%3B%20filename%3Dyoutube-dl&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-12-09 06:15:01--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1039520/1ae5cc00-c66b-11eb-8853-1cd0f5317557?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211209T061500Z&X-Amz-Expires=300&X-Amz-Signature=d5c0630e4ceb1a111516ecc5e5778bbfec11cb40a4e51df33cdfe26736b29e9e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1039520&response-content-disposition=attachment%3B%20filename%3Dyoutube-dl&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1840311 (1.8M) [application/octet-stream]\n",
            "Saving to: ‘youtube-dl’\n",
            "\n",
            "youtube-dl          100%[===================>]   1.75M  1.10MB/s    in 1.6s    \n",
            "\n",
            "2021-12-09 06:15:03 (1.10 MB/s) - ‘youtube-dl’ saved [1840311/1840311]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# load youtube-dl\n",
        "!wget https://yt-dl.org/downloads/latest/youtube-dl -O youtube-dl\n",
        "!chmod a+rx youtube-dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34TQRxCd2AaW",
        "outputId": "c1f815cc-5bdb-4692-fa61-c3eea375faff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]Can not load video OPcZlXYcdMA, broken link\n",
            "5it [14:43, 176.64s/it]Process ForkPoolWorker-8:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 733, in next\n",
            "    item = self._items.popleft()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"load_videos.py\", line 100, in <module>\n",
            "Process ForkPoolWorker-6:\n",
            "    for chunks_data in tqdm(pool.imap_unordered(run, zip(video_ids, args_list))):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/_tqdm.py\", line 931, in __iter__\n",
            "Traceback (most recent call last):\n",
            "    for obj in iterable:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 737, in next\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"load_videos.py\", line 52, in run\n",
            "    if (i * ref_fps >= entry['start'] * fps) and (i * ref_fps < entry['end'] * fps):\n",
            "KeyboardInterrupt\n",
            "    self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 296, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"load_videos.py\", line 72, in run\n",
            "    save(os.path.join(args.out_folder, partition, path), entry['frames'], args.format)\n",
            "  File \"/content/drive/My Drive/articulated-animation-main/articulated-animation-main/video-preprocessing/util.py\", line 118, in save\n",
            "    imageio.mimsave(path, frames)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imageio/core/functions.py\", line 341, in mimwrite\n",
            "    writer.append_data(im)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imageio/core/format.py\", line 492, in append_data\n",
            "    return self._append_data(im, total_meta)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imageio/plugins/ffmpeg.py\", line 661, in _append_data\n",
            "    self._proc.stdin.write(im.tostring())\n",
            "KeyboardInterrupt\n",
            "Process ForkPoolWorker-2:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"load_videos.py\", line 60, in run\n",
            "    crop = img_as_ubyte(resize(crop, args.image_shape, anti_aliasing=True))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/skimage/transform/_warps.py\", line 144, in resize\n",
            "    cval=cval, mode=mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/ndimage/filters.py\", line 286, in gaussian_filter\n",
            "    mode, cval, truncate)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/ndimage/filters.py\", line 204, in gaussian_filter1d\n",
            "    return correlate1d(input, weights, axis, output, mode, cval, 0)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/ndimage/filters.py\", line 92, in correlate1d\n",
            "    origin)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python load_videos.py --metadata ../video-preprocessing/taichi-metadata.csv --format .mp4 --out_folder ../data/taichi-png --workers 8 --image_shape 256,256\n",
        "#video-preprocessing 파일에있는 taichi 실행시킴\n",
        "#쫌 돌려놓으면 밑밑에 셀 실행되는듯?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSf-LfDqBl7p",
        "outputId": "7d2db721-4127-45c0-8670-0649c053d008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/articulated-animation-main/articulated-animation-main\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/articulated-animation-main/articulated-animation-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7yEfSRkKnwa"
      },
      "outputs": [],
      "source": [
        "# import torch,gc\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "#CUDA out of memory. Tried to allocate 216.00 MiB  이거 해결할려면 넣으라는데... 안됨 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L31Sjc9qTFz",
        "outputId": "088317bd-9f2d-4700-a2dc-d53dd64a7602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Use predefined train-test split.\n",
            "Training...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:05<00:00, 112MB/s]\n",
            "  0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:4004: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  \"Default grid_sample and affine_grid behavior has changed \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/drive/My Drive/articulated-animation-main/articulated-animation-main/logger.py:149: FutureWarning: `draw.circle` is deprecated in favor of `draw.disk`.`draw.circle` will be removed in version 0.19\n",
            "  rr, cc = circle(kp[1], kp[0], self.kp_size, shape=image.shape[:2])\n",
            "  3% 3/100 [22:53<12:20:15, 457.90s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 103, in <module>\n",
            "    train(config, generator, region_predictor, bg_predictor, opt.checkpoint, log_dir, dataset, opt.device_ids)\n",
            "  File \"/content/drive/My Drive/articulated-animation-main/articulated-animation-main/train.py\", line 52, in train\n",
            "    losses, generated = model(x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 166, in forward\n",
            "    return self.module(*inputs[0], **kwargs[0])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/My Drive/articulated-animation-main/articulated-animation-main/modules/model.py\", line 190, in forward\n",
            "    transformed_frame = transform.transform_frame(x['driving'])\n",
            "  File \"/content/drive/My Drive/articulated-animation-main/articulated-animation-main/modules/model.py\", line 103, in transform_frame\n",
            "    grid = make_coordinate_grid(frame.shape[2:], type=frame.type()).unsqueeze(0)\n",
            "  File \"/content/drive/My Drive/articulated-animation-main/articulated-animation-main/modules/util.py\", line 51, in make_coordinate_grid\n",
            "    x = torch.arange(w).type(type)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python run.py --config config/taichi256.yaml --device_ids 0\n",
        "#taichi246.yaml batch size 14->4로 줄임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPG3iCZlqVQ8"
      },
      "source": [
        "## --------------------------------------------------------------------\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python run.py --checkpoint log/taichi256/cpk.pth --config log/taichi256/taichi256.yaml --device_ids 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNxvEM53H6cj",
        "outputId": "134aefc4-4965-407b-bd29-2040807b3e55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Use predefined train-test split.\n",
            "Training...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "  0% 0/98 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:4004: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  \"Default grid_sample and affine_grid behavior has changed \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/drive/MyDrive/articulated-animation-main/articulated-animation-main/logger.py:149: FutureWarning: `draw.circle` is deprecated in favor of `draw.disk`.`draw.circle` will be removed in version 0.19\n",
            "  rr, cc = circle(kp[1], kp[0], self.kp_size, shape=image.shape[:2])\n",
            " 10% 10/98 [1:11:42<10:31:04, 430.28s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 103, in <module>\n",
            "    train(config, generator, region_predictor, bg_predictor, opt.checkpoint, log_dir, dataset, opt.device_ids)\n",
            "  File \"/content/drive/MyDrive/articulated-animation-main/articulated-animation-main/train.py\", line 55, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 307, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 156, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p60HTgsGIJTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e9ipaXdWJVCM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "deeplearning1203.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}